Title: Reading roundup
Date: 2016-01-08
Slug: reading-roundup-2016-01-08
Author: Daniel S. Standage
Category: roundup
Tags: 
Summary: Roundup of links from the last week's worth of interesting reads.

## [This Bloomberg piece on academic publishing and the economics of status](http://www.bloombergview.com/articles/2016-01-05/academic-publishing-is-all-about-status)

> This trend will be familiar to anyone who has looked at admission rates to top universities.
> Despite ever-rising tuition costs and the growth of much-cheaper online alternatives, the highest-status universities keep getting more selective.
> The best way to understand this, I think, is to see both academic journals and top universities less as purveyors of information or knowledge than as dispensers of status.
> Information may want to be free, but status will always be scarce.

## [This blog post on sustaining research software](http://ivory.idyll.org/blog/2016-sustaining-research-software-development.html)

> Software is fast becoming a *sine qua non* in research, and researchers and funding agencies have been trying with increasing urgency to figure out how to support sustainable software development.
> There's a whole NSF program devoted to sustainable research software, and I think it's fair to say that one of the main subsurface goals of the BD2K program is to tackle the question of software (PSA: data isn't much use without software).
> The USDA and bio bits of DOE are also running smack into the problem that the research programs they fund are utterly dependent on software, yet investments in software are often secondary and rarely yield software that is usable past the end of the grant.
> It turns out that software development for research is a rather intransigent beast.

## [This preprint on the state of software in (evolutionary) biology](http://biorxiv.org/content/early/2015/11/16/031930.abstract)

> A topic that has received little attention in this context is the code quality of widely used codes.
> Unfortunately, the majority of users tend to blindly trust software and the results it produces.

## [This interesting analysis of references to dates and a suprising effect from OCR](http://drhagen.com/blog/the-missing-11th-of-the-month/)

> So where did the rest of the missing 11th go?
> Well, starting in the 1860s, the Google algorithm starts to make a rather peculiar error—it misreads 11th as nth.

## [This Guardian article on showmanship in science](http://www.theguardian.com/science/blog/2015/nov/26/why-combining-science-and-showmanship-risks-the-future-of-research)

> For many years, medicine, dinosaurs, space travel, and human origins have all been highly visible and widely entertaining scientific topics.
> And for many years, we have relied on evaluation by editorial and professional peer review in scientific journals, evaluative reporting by science journalists, and individual judgment of educated citizens to place new scientific claims into proper perspective.
> ?Under those conditions, the trend toward science showmanship was arguably tolerable because it usually rested on a foundation of solid science.
> When it doesn’t, it becomes bad reality TV that pleases sponsors but shouldn’t be confused for knowledge about process or result.

## [This gist describing "sane git diffs for Jupyter notebook"](https://gist.github.com/matsen/37521f504a14aede644d)

Since Jupyter notebooks are stored in JSON format, this converts them to Markdown for diffs you can actually interpret.

## [This Python package for managing large authors lists in LaTeX files](https://github.com/idoerg/authorator)

I *really* hope I never have to use something like this!

## [This blog post on research group dynamics](http://pgbovine.net/research-group-dynamics.htm)

> A study at Google found five key dynamics that make for successful teams within the company: psychological safety, dependability, structure & clarity, meaning of work, and impact of work.
> These findings can be adapted to improving research group dynamics in academia.